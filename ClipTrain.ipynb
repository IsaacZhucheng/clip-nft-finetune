{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c062e9-a630-4498-af56-fb2736c2807d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorboard\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m251.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m247.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.21.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (59.3.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m309.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.38.4)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m288.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.20.3)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (2.28.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m271.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m282.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m262.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.14.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m280.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (6.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.13.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m276.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, werkzeug, tensorboard-data-server, pyasn1-modules, oauthlib, grpcio, cachetools, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.0\n",
      "    Uninstalling Werkzeug-1.0.0:\n",
      "      Successfully uninstalled Werkzeug-1.0.0\n",
      "Successfully installed absl-py-1.4.0 cachetools-5.3.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 grpcio-1.51.3 markdown-3.4.1 oauthlib-3.2.2 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.2.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.42.1)\n",
      "Collecting wcwidth>=0.2.5\n",
      "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: wcwidth, ftfy\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.1.8\n",
      "    Uninstalling wcwidth-0.1.8:\n",
      "      Successfully uninstalled wcwidth-0.1.8\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed ftfy-6.1.1 wcwidth-0.2.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-ymh7iban\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-ymh7iban\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /opt/conda/lib/python3.7/site-packages (from clip==1.0) (6.1.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from clip==1.0) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from clip==1.0) (4.42.1)\n",
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m220.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m247.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from ftfy->clip==1.0) (0.2.6)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m239.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->clip==1.0) (4.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m161.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m219.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m299.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (59.3.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (0.38.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->clip==1.0) (9.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->clip==1.0) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->clip==1.0) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->clip==1.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->clip==1.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->clip==1.0) (1.26.14)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369408 sha256=e48d89709603828462e478d895c6541cb2d7fd8ed1da8fd70f748286ee4bede4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-j84r454g/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
      "Successfully built clip\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision, clip\n",
      "Successfully installed clip-1.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 torchvision-0.14.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-1.9.4-py3-none-any.whl (827 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.8/827.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (4.4.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (20.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.13.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (2023.1.0)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.6/518.6 kB\u001b[0m \u001b[31m306.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.57.0\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m253.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightning-utilities>=0.6.0.post0\n",
      "  Downloading lightning_utilities-0.7.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.28.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.7/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from lightning-utilities>=0.6.0.post0->pytorch_lightning) (6.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.1->pytorch_lightning) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=17.1->pytorch_lightning) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch>=1.10.0->pytorch_lightning) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch>=1.10.0->pytorch_lightning) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch>=1.10.0->pytorch_lightning) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch>=1.10.0->pytorch_lightning) (11.7.99)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->pytorch_lightning) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->pytorch_lightning) (59.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (0.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.0.0->lightning-utilities>=0.6.0.post0->pytorch_lightning) (3.13.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.8)\n",
      "Installing collected packages: tqdm, lightning-utilities, torchmetrics, pytorch_lightning\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.42.1\n",
      "    Uninstalling tqdm-4.42.1:\n",
      "      Successfully uninstalled tqdm-4.42.1\n",
      "Successfully installed lightning-utilities-0.7.1 pytorch_lightning-1.9.4 torchmetrics-0.11.3 tqdm-4.64.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorboard\n",
    "! pip install ftfy regex tqdm\n",
    "! pip install git+https://github.com/openai/CLIP.git\n",
    "! pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8334fd8a-cc9f-48e8-80d0-39b02833ec8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py:119: PkgResourcesDeprecationWarning: 4.0.0-unsupported is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from random import randint, choice\n",
    "\n",
    "import PIL\n",
    "import argparse\n",
    "import clip\n",
    "import torch\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from pytorch_lightning import LightningDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98061a-dee0-43d8-b89a-f856c39ef2f7",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb707d30-78b8-4fb0-9a44-c5995dd36c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextImageDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data: str,\n",
    "                 shuffle=False,\n",
    "                 custom_tokenizer=False\n",
    "                 ):\n",
    "        \"\"\"Create a text image dataset from a json file with img/text pair, img should be preprocessed already by CLIP \"ViT-B/32\" Preprocessor\n",
    "        Args:\n",
    "            data (str): Path of the json file for the input pair. key being preprocessed image file location, value being the corresponding description\n",
    "            shuffle (bool, optional): Whether or not to have shuffling behavior during sampling. Defaults to False.\n",
    "            custom_tokenizer (bool, optional): Whether or not there is a custom tokenizer. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        \n",
    "        with open(data, 'r') as f:\n",
    "            self.img_to_text = json.load(f)\n",
    "        self.imgs = list(self.img_to_text.keys())\n",
    "            \n",
    "        self.custom_tokenizer = custom_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def fix_img(self, img):\n",
    "        return img.convert('RGB') if img.mode != 'RGB' else img\n",
    "\n",
    "    def random_sample(self):\n",
    "        return self.__getitem__(randint(0, self.__len__() - 1))\n",
    "\n",
    "    def sequential_sample(self, ind):\n",
    "        if ind >= self.__len__() - 1:\n",
    "            return self.__getitem__(0)\n",
    "        return self.__getitem__(ind + 1)\n",
    "\n",
    "    def skip_sample(self, ind):\n",
    "        if self.shuffle:\n",
    "            return self.random_sample()\n",
    "        return self.sequential_sample(ind=ind)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "\n",
    "        image_file = self.imgs[ind]\n",
    "        description = self.img_to_text[image_file]\n",
    "\n",
    "        try:\n",
    "            tokenized_text = description if self.custom_tokenizer else clip.tokenize(description, truncate=True)[0]\n",
    "        except:\n",
    "            print(f\"An exception occurred trying to load contract description {image_file}.\")\n",
    "            print(f\"Skipping index {ind}\")\n",
    "            return self.skip_sample(ind)\n",
    "        \n",
    "        try:\n",
    "            image_tensor = torch.load(image_file)\n",
    "        except (PIL.UnidentifiedImageError, OSError) as corrupt_image_exceptions:\n",
    "            print(f\"An exception occurred trying to load file {image_file}.\")\n",
    "            print(f\"Skipping index {ind}\")\n",
    "            return self.skip_sample(ind)\n",
    "\n",
    "        # Success\n",
    "        return image_tensor, tokenized_text, image_file.split('/')[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c16bd6-138a-45d9-832f-16e6aed21e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextImageDataModule(LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 data: str,\n",
    "                 batch_size: int,\n",
    "                 num_workers=0,\n",
    "                 shuffle=False,\n",
    "                 custom_tokenizer=None,\n",
    "                 eval=False\n",
    "                 ):\n",
    "        \"\"\"Create a text image data module from directories with congruent text and image names.\n",
    "        Args:\n",
    "            data (str): Json file containing images and text pairs\n",
    "            batch_size (int): The batch size of each dataloader.\n",
    "            num_workers (int, optional): The number of workers in the DataLoader. Defaults to 0.\n",
    "            shuffle (bool, optional): Whether or not to have shuffling behavior during sampling. Defaults to False.\n",
    "            custom_tokenizer (transformers.AutoTokenizer, optional): The tokenizer to use on the text. Defaults to None.\n",
    "            eval (bool, optional): Eval mode or not\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.shuffle = shuffle\n",
    "        self.custom_tokenizer = custom_tokenizer\n",
    "        if eval:\n",
    "            self.drop_last = False\n",
    "        else:\n",
    "            self.drop_last = True\n",
    "        \n",
    "    \n",
    "    # Used later for scirpting\n",
    "    @staticmethod\n",
    "    def add_argparse_args(parent_parser):\n",
    "        parser = argparse.ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--data', type=str, required=True, help='json file of the text/vision pair')\n",
    "        parser.add_argument('--batch_size', type=int, help='size of the batch')\n",
    "        parser.add_argument('--num_workers', type=int, default=0, help='number of workers for the dataloaders')\n",
    "        parser.add_argument('--shuffle', type=bool, default=False, help='whether to use shuffling during sampling')\n",
    "        return parser\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = TextImageDataset(self.data, shuffle=self.shuffle, custom_tokenizer=not self.custom_tokenizer is None)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset, batch_size=self.batch_size, shuffle=self.shuffle, num_workers=self.num_workers, drop_last=self.drop_last, collate_fn=self.dl_collate_fn) # \n",
    "    def dl_collate_fn(self, batch):\n",
    "        if self.custom_tokenizer is None:\n",
    "            return torch.stack([row[0] for row in batch]), torch.stack([row[1] for row in batch]), [row[2] for row in batch]\n",
    "        else:\n",
    "            return torch.stack([row[0] for row in batch]), self.custom_tokenizer([row[1] for row in batch], padding=True, truncation=True, return_tensors=\"pt\"), [row[2] for row in batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5954bb-bb35-44e6-a1c6-850c83f5fbca",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb94d16b-8f0a-4f5f-8ddd-1dd4c95aab3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # If using GPU then use mixed precision training.\n",
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False) #Must set jit=False for training\n",
    "#https://github.com/openai/CLIP/issues/57\n",
    "def convert_models_to_fp32(model): \n",
    "    for p in model.parameters(): \n",
    "        p.data = p.data.float() \n",
    "        p.grad.data = p.grad.data.float() \n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_index, tb_writer, steps, loss_img, loss_txt):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        images,texts,_ = batch \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images = images.to(device)\n",
    "        texts = texts.to(device)\n",
    "        logits_per_image, logits_per_text = model(image=images, text=texts)\n",
    "\n",
    "        ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
    "\n",
    "        total_loss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
    "        total_loss.backward()\n",
    "        \n",
    "\n",
    "        if device == \"cpu\":\n",
    "             optimizer.step()\n",
    "        else : \n",
    "            convert_models_to_fp32(model)\n",
    "            optimizer.step()\n",
    "            clip.model.convert_weights(model)\n",
    "            \n",
    "        # Gather data and report\n",
    "        running_loss += total_loss.item()\n",
    "        if i % steps == steps-1:\n",
    "            last_loss = running_loss / steps # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17d085a3-09d2-46de-9b22-8bc14c996315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resume Model\n",
    "model.load_state_dict(torch.load('./model_checkpoint/model_lr_1e-06_bs_64_20230302_213906_33'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "199a954d-1373-4f43-a578-c3a686f89348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 35:\n",
      "  batch 50 loss: 4.2980859375\n",
      "  batch 100 loss: 4.283828125\n",
      "  batch 150 loss: 4.272265625\n",
      "  batch 200 loss: 4.264375\n",
      "  batch 250 loss: 4.27109375\n",
      "  batch 300 loss: 4.276875\n",
      "LOSS train 4.276875 valid 4.87109375\n",
      "EPOCH 36:\n",
      "  batch 50 loss: 4.26734375\n",
      "  batch 100 loss: 4.264140625\n",
      "  batch 150 loss: 4.292265625\n",
      "  batch 200 loss: 4.2857421875\n",
      "  batch 250 loss: 4.2488671875\n",
      "  batch 300 loss: 4.28109375\n",
      "LOSS train 4.28109375 valid 4.87109375\n",
      "EPOCH 37:\n",
      "  batch 50 loss: 4.3000390625\n",
      "  batch 100 loss: 4.27421875\n",
      "  batch 150 loss: 4.28140625\n",
      "  batch 200 loss: 4.25203125\n",
      "  batch 250 loss: 4.26859375\n",
      "  batch 300 loss: 4.295\n",
      "LOSS train 4.295 valid 4.87109375\n",
      "EPOCH 38:\n",
      "  batch 50 loss: 4.2498828125\n",
      "  batch 100 loss: 4.2833203125\n",
      "  batch 150 loss: 4.269921875\n",
      "  batch 200 loss: 4.3032421875\n",
      "  batch 250 loss: 4.31109375\n",
      "  batch 300 loss: 4.270703125\n",
      "LOSS train 4.270703125 valid 4.87109375\n",
      "EPOCH 39:\n",
      "  batch 50 loss: 4.28765625\n",
      "  batch 100 loss: 4.2790625\n",
      "  batch 150 loss: 4.2853125\n",
      "  batch 200 loss: 4.2826171875\n",
      "  batch 250 loss: 4.2815234375\n",
      "  batch 300 loss: 4.266484375\n",
      "LOSS train 4.266484375 valid 4.87109375\n",
      "EPOCH 40:\n",
      "  batch 50 loss: 4.278515625\n",
      "  batch 100 loss: 4.265078125\n",
      "  batch 150 loss: 4.28546875\n",
      "  batch 200 loss: 4.26484375\n",
      "  batch 250 loss: 4.2871875\n",
      "  batch 300 loss: 4.279609375\n",
      "LOSS train 4.279609375 valid 4.87109375\n",
      "EPOCH 41:\n",
      "  batch 50 loss: 4.28453125\n",
      "  batch 100 loss: 4.23671875\n",
      "  batch 150 loss: 4.2540625\n",
      "  batch 200 loss: 4.278671875\n",
      "  batch 250 loss: 4.31109375\n",
      "  batch 300 loss: 4.294140625\n",
      "LOSS train 4.294140625 valid 4.87109375\n",
      "EPOCH 42:\n",
      "  batch 50 loss: 4.2808984375\n",
      "  batch 100 loss: 4.2553125\n",
      "  batch 150 loss: 4.334609375\n",
      "  batch 200 loss: 4.2801953125\n",
      "  batch 250 loss: 4.2830078125\n",
      "  batch 300 loss: 4.265625\n",
      "LOSS train 4.265625 valid 4.87109375\n",
      "EPOCH 43:\n",
      "  batch 50 loss: 4.274453125\n",
      "  batch 100 loss: 4.246484375\n",
      "  batch 150 loss: 4.2921875\n",
      "  batch 200 loss: 4.2501171875\n",
      "  batch 250 loss: 4.296875\n",
      "  batch 300 loss: 4.272890625\n",
      "LOSS train 4.272890625 valid 4.87109375\n",
      "EPOCH 44:\n",
      "  batch 50 loss: 4.3201171875\n",
      "  batch 100 loss: 4.2675390625\n",
      "  batch 150 loss: 4.2590625\n",
      "  batch 200 loss: 4.27984375\n",
      "  batch 250 loss: 4.2663671875\n",
      "  batch 300 loss: 4.25796875\n",
      "LOSS train 4.25796875 valid 4.87109375\n",
      "EPOCH 45:\n",
      "  batch 50 loss: 4.3134375\n",
      "  batch 100 loss: 4.306953125\n",
      "  batch 150 loss: 4.27328125\n",
      "  batch 200 loss: 4.240234375\n",
      "  batch 250 loss: 4.248125\n",
      "  batch 300 loss: 4.28109375\n",
      "LOSS train 4.28109375 valid 4.87109375\n",
      "EPOCH 46:\n",
      "  batch 50 loss: 4.314296875\n",
      "  batch 100 loss: 4.2803515625\n",
      "  batch 150 loss: 4.236640625\n",
      "  batch 200 loss: 4.25453125\n",
      "  batch 250 loss: 4.2918359375\n",
      "  batch 300 loss: 4.2565625\n",
      "LOSS train 4.2565625 valid 4.87109375\n",
      "EPOCH 47:\n",
      "  batch 50 loss: 4.302578125\n",
      "  batch 100 loss: 4.27828125\n",
      "  batch 150 loss: 4.282890625\n",
      "  batch 200 loss: 4.24828125\n",
      "  batch 250 loss: 4.26640625\n",
      "  batch 300 loss: 4.2909375\n",
      "LOSS train 4.2909375 valid 4.87109375\n",
      "EPOCH 48:\n",
      "  batch 50 loss: 4.2898828125\n",
      "  batch 100 loss: 4.2765625\n",
      "  batch 150 loss: 4.27734375\n",
      "  batch 200 loss: 4.281328125\n",
      "  batch 250 loss: 4.258046875\n",
      "  batch 300 loss: 4.274765625\n",
      "LOSS train 4.274765625 valid 4.87109375\n",
      "EPOCH 49:\n",
      "  batch 50 loss: 4.301171875\n",
      "  batch 100 loss: 4.275703125\n",
      "  batch 150 loss: 4.2620703125\n",
      "  batch 200 loss: 4.26609375\n",
      "  batch 250 loss: 4.269296875\n",
      "  batch 300 loss: 4.273671875\n",
      "LOSS train 4.273671875 valid 4.87109375\n",
      "EPOCH 50:\n",
      "  batch 50 loss: 4.3017578125\n",
      "  batch 100 loss: 4.3123046875\n",
      "  batch 150 loss: 4.271640625\n",
      "  batch 200 loss: 4.249375\n",
      "  batch 250 loss: 4.26328125\n",
      "  batch 300 loss: 4.2646875\n",
      "LOSS train 4.2646875 valid 4.87109375\n",
      "EPOCH 51:\n",
      "  batch 50 loss: 4.2758984375\n",
      "  batch 100 loss: 4.253203125\n",
      "  batch 150 loss: 4.2615234375\n",
      "  batch 200 loss: 4.29125\n",
      "  batch 250 loss: 4.299296875\n",
      "  batch 300 loss: 4.26921875\n",
      "LOSS train 4.26921875 valid 4.87109375\n",
      "EPOCH 52:\n",
      "  batch 50 loss: 4.26203125\n",
      "  batch 100 loss: 4.3155078125\n",
      "  batch 150 loss: 4.290859375\n",
      "  batch 200 loss: 4.270390625\n",
      "  batch 250 loss: 4.24609375\n",
      "  batch 300 loss: 4.2734375\n",
      "LOSS train 4.2734375 valid 4.87109375\n",
      "EPOCH 53:\n",
      "  batch 50 loss: 4.33828125\n",
      "  batch 100 loss: 4.2267578125\n",
      "  batch 150 loss: 4.253828125\n",
      "  batch 200 loss: 4.308984375\n",
      "  batch 250 loss: 4.29984375\n",
      "  batch 300 loss: 4.24546875\n",
      "LOSS train 4.24546875 valid 4.87109375\n",
      "EPOCH 54:\n",
      "  batch 50 loss: 4.33640625\n",
      "  batch 100 loss: 4.3040625\n",
      "  batch 150 loss: 4.25984375\n",
      "  batch 200 loss: 4.240546875\n",
      "  batch 250 loss: 4.2514453125\n",
      "  batch 300 loss: 4.2599609375\n",
      "LOSS train 4.2599609375 valid 4.87109375\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 34\n",
    "steps_to_report = 50\n",
    "\n",
    "SAVED_PATH = './model_checkpoint'\n",
    "EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-8\n",
    "\n",
    "TRAIN_JSON = './data/train_50000.json'\n",
    "TEST_JSON = './data/test_50000.json'\n",
    "\n",
    "TrainDataModule = TextImageDataModule(TRAIN_JSON, BATCH_SIZE, num_workers=2, shuffle=True)\n",
    "TrainDataModule.setup()\n",
    "train_loader = TrainDataModule.train_dataloader()\n",
    "\n",
    "TestDataModule = TextImageDataModule(TEST_JSON, BATCH_SIZE, num_workers=2)\n",
    "TestDataModule.setup()\n",
    "validation_loader = TestDataModule.train_dataloader()\n",
    "\n",
    "\n",
    "loss_img = torch.nn.CrossEntropyLoss()\n",
    "loss_txt = torch.nn.CrossEntropyLoss()\n",
    "## \n",
    "\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "\n",
    "# https://github.com/openai/CLIP/issues/150\n",
    "# As Suggested, turn on eval mode even in training\n",
    "# model.eval()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9,0.98), eps=1e-6,weight_decay=0.02) #Params used from paper, the lr is smaller, safer for fine tuning to new dataset\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    \n",
    "    model.train()\n",
    "    avg_loss = train_one_epoch(epoch_number, writer, steps_to_report, loss_img, loss_txt)\n",
    "    model.eval()\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, vbatch in enumerate(validation_loader):\n",
    "            images,texts,_ = vbatch \n",
    "\n",
    "            images = images.to(device)\n",
    "            texts = texts.to(device)\n",
    "            logits_per_image, logits_per_text = model(image=images, text=texts)\n",
    "            ground_truth = torch.arange(len(images),dtype=torch.long,device=device)\n",
    "\n",
    "            vloss = (loss_img(logits_per_image,ground_truth) + loss_txt(logits_per_text,ground_truth))/2\n",
    "            \n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = './model_checkpoint/model_lr_{}_bs_{}_{}_{}'.format(LEARNING_RATE, BATCH_SIZE, timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aacb7e0d-691c-4c98-bb24-83950ca090e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e4785ae-2a17-48db-a476-0573d6bfcbe1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tbparse\n",
      "  Downloading tbparse-0.0.7-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from tbparse) (1.3.5)\n",
      "Requirement already satisfied: tensorboard>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tbparse) (2.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.3.0->tbparse) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.3.0->tbparse) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.3.0->tbparse) (1.21.6)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (59.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (1.51.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (2.28.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (3.4.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (1.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (2.16.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (0.38.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.0.0->tbparse) (1.8.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.0.0->tbparse) (1.14.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.0.0->tbparse) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.0.0->tbparse) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.0.0->tbparse) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.0.0->tbparse) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.0.0->tbparse) (6.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.0.0->tbparse) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.0.0->tbparse) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.0.0->tbparse) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.0.0->tbparse) (2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard>=2.0.0->tbparse) (2.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.0.0->tbparse) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.0.0->tbparse) (3.13.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.0.0->tbparse) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.0.0->tbparse) (3.2.2)\n",
      "Installing collected packages: tbparse\n",
      "Successfully installed tbparse-0.0.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tbparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8e2df6c-e821-4f3c-8fe0-7f7b5405cfba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step                           tag     value\n",
      "0     50                    Loss/train  2.975039\n",
      "1    108                    Loss/train  1.253066\n",
      "2    166                    Loss/train  0.480698\n",
      "3    224                    Loss/train  0.285620\n",
      "4    282                    Loss/train  0.220945\n",
      "5      1  Training vs. Validation Loss  2.975039\n",
      "6      1  Training vs. Validation Loss  2.560547\n",
      "7      2  Training vs. Validation Loss  1.253066\n",
      "8      2  Training vs. Validation Loss  3.060547\n",
      "9      3  Training vs. Validation Loss  0.480698\n",
      "10     3  Training vs. Validation Loss  3.791016\n",
      "11     4  Training vs. Validation Loss  0.285620\n",
      "12     4  Training vs. Validation Loss  4.070312\n",
      "13     5  Training vs. Validation Loss  0.220945\n",
      "14     5  Training vs. Validation Loss  4.765625\n"
     ]
    }
   ],
   "source": [
    "from tbparse import SummaryReader\n",
    "log_dir = \"runs/fashion_trainer_20230301_191159\"\n",
    "reader = SummaryReader(log_dir)\n",
    "df = reader.scalars\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b341ee-128f-4f17-a725-1072ee23555c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
